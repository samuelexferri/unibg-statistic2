{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# RANDOM CROSS VALIDATION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## MODEL SELECTION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pedix = str.maketrans(\"3\", \"₃\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "nh3_nc = xr.load_dataset('../datasets/CAMS-GLOB-ANT_Glb_0.1x0.1_anthro_nh3_v4.2_monthly_lombardia.nc') # Copernicus (0.1°x0.1°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nh3 = utils.xarray2pandas(nh3_nc.agl, 6, 17).to_period('M')\n",
    "\n",
    "train_data, test_data = utils.ts_train_test_split(nh3, .8)\n",
    "\n",
    "train_data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "def random_training_validation_window(ts, size, validation_size):\n",
    "\n",
    "    n = len(ts)\n",
    "\n",
    "    start = random.randint(0, int(n*(1-size)) - validation_size)\n",
    "    end = start + int(n*size)\n",
    "    \n",
    "    return ts[start:end], ts[end:end+validation_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_forecasts(model, ts, times, refit=False):\n",
    "    \n",
    "    predictions = []\n",
    "    errors = []\n",
    "\n",
    "    for i in range(len(ts)):\n",
    "        prediction = model.forecast()\n",
    "        model = model.append([prediction.values[0]], refit=refit)\n",
    "        predictions.append(prediction.values[0])\n",
    "        errors.append(ts.values[i] - prediction.values[0])\n",
    "    \n",
    "    return predictions, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(ts):\n",
    "    errors = pd.Series(ts)\n",
    "    n = len(ts)\n",
    "    data = np.asarray(ts)\n",
    "    mean = np.mean(data)\n",
    "    c0 = np.sum((data - mean) ** 2) / float(n)\n",
    "\n",
    "    def r(h):\n",
    "        return ((data[:n - h] - mean) * (data[h:] - mean)).sum() / float(n) / c0\n",
    "\n",
    "    lags = np.arange(n) + 1\n",
    "    return list(map(r, lags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import pandas as pd\n",
    "\n",
    "def random_cross_validation(ts, order, seasonal_order, times=1, verbose=False):\n",
    "\n",
    "    aics = []\n",
    "    bics = []\n",
    "    rmses = []\n",
    "    resid_acfs = []\n",
    "\n",
    "    for i in range(times):\n",
    "\n",
    "        # window size\n",
    "        train_months = 180\n",
    "        validation_months = 12\n",
    "        train_data, validation_data = random_training_validation_window(ts, train_months/len(ts), validation_months)\n",
    "\n",
    "        # assert(len(train_data) == train_months)\n",
    "        # assert(len(validation_data) == validation_months)\n",
    "\n",
    "        model = ARIMA(endog=train_data, order=order, seasonal_order=seasonal_order).fit()\n",
    "\n",
    "        aics.append(model.aic)\n",
    "        bics.append(model.bic)\n",
    "\n",
    "        # prediction out of sample\n",
    "        predictions, errors = multiple_forecasts(model=model, ts=validation_data, times=len(validation_data), refit=False)\n",
    "        rmse = np.sqrt(np.mean(((predictions - validation_data.values) ** 2)))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "        resid_acf = np.mean(np.abs(acf(model.resid, nlags=24)))\n",
    "        resid_acfs.append(resid_acf)\n",
    "\n",
    "    return np.mean(aics), np.mean(bics), np.mean(rmses), np.mean(resid_acfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMAX(p,d,q,P,D,Q,s)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def model_selection(ts, cv_iterations=1, verbose=False):\n",
    "    \n",
    "    p_list = [1, 2, 3, 4]\n",
    "    q_list = [0, 1, 2]\n",
    "    P_list = [1]\n",
    "    Q_list = [0, 1]\n",
    "    s_list = [12]\n",
    "\n",
    "    results = {}\n",
    "    idx = 0\n",
    "\n",
    "    for p in p_list:\n",
    "       for q in q_list:\n",
    "            for P in P_list:\n",
    "                for Q in Q_list:\n",
    "                    for s in s_list:\n",
    "                        model_name = 'SARIMA(p={}, d=0, q={}, P={}, D=0, Q={}, s={})'.format(p, q, P, Q, s)\n",
    "                        model_idx = idx\n",
    "\n",
    "                        if verbose: print('{}: {}'.format(model_idx, model_name))\n",
    "                        \n",
    "                        aic, bic, rmse, resid_acf = random_cross_validation(ts=ts, order=(p,0,q), seasonal_order=(P,0,Q,s), times=cv_iterations)\n",
    "\n",
    "                        results[model_name] = {\n",
    "                            'index' : model_idx,\n",
    "                            'order' : (p,0,q),\n",
    "                            'seasonal_order' : (P,0,Q,s),\n",
    "                            'aic' : aic,\n",
    "                            'bic' : bic,\n",
    "                            'rmse' : rmse,\n",
    "                            'acf': resid_acf\n",
    "                            }\n",
    "\n",
    "                        idx += 1\n",
    "                    \n",
    "                    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = model_selection(train_data, cv_iterations=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aics = [v['aic'] for k, v in results.items()]\n",
    "bics = [v['bic'] for k, v in results.items()]\n",
    "rmses = [v['rmse'] for k, v in results.items()]\n",
    "acfs = [v['acf'] for k, v in results.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tick(order, seasonal_order):\n",
    "    p, d, q = order\n",
    "    P, D, Q, s = seasonal_order\n",
    "    return str((p,q,P,Q))\n",
    "\n",
    "ticks = [tick(v['order'], v['seasonal_order']) for k, v in sorted(results.items(), key=lambda item: item[1]['index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(18,5))\n",
    "indices = np.arange(0, len(results), 2)\n",
    "\n",
    "axs[0].plot(aics)\n",
    "axs[0].set_title('AIC (p,0,q,P,0,Q), s=12')\n",
    "axs[0].set_xticks(indices)\n",
    "axs[0].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "axs[1].plot(bics)\n",
    "axs[1].set_title('BIC (p,0,q,P,0,Q), s=12')\n",
    "axs[1].set_xticks(indices)\n",
    "axs[1].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "axs[2].plot(rmses)\n",
    "axs[2].set_title('RMSE (p,0,q,P,0,Q), s=12')\n",
    "axs[2].set_xticks(indices)\n",
    "axs[2].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "axs[3].plot(acfs)\n",
    "axs[3].set_title('ACF (p,0,q,P,0,Q), s=12')\n",
    "axs[3].set_xticks(indices)\n",
    "axs[3].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min AIC: {}, min BIC {}, min RMSE {}, min ACF'.format(np.argmin(aics), np.argmin(bics), np.argmin(rmses), np.argmin(bics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_aic_model = [v for k,v in results.items() if v['aic'] == np.min(aics)][0]\n",
    "min_aic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bic_model = [v for k,v in results.items() if v['bic'] == np.min(bics)][0]\n",
    "min_bic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rmse_model = [v for k,v in results.items() if v['rmse'] == np.min(rmses)][0]\n",
    "min_rmse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_acf_model = [v for k,v in results.items() if v['acf'] == np.min(acfs)][0]\n",
    "min_acf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select models with aic near the minimum found\n",
    "min_aic = np.min(aics)\n",
    "candidate_models = [v for k,v in results.items() if v['aic'] < min_aic*0.95 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aics = [v['aic'] for v in candidate_models]\n",
    "bics = [v['bic'] for v in candidate_models]\n",
    "rmses = [v['rmse'] for v in candidate_models]\n",
    "acfs = [v['acf'] for v in candidate_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = [tick(v['order'], v['seasonal_order']) for v in candidate_models]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15,8))\n",
    "indices = np.arange(0, len(candidate_models), 1)\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "\n",
    "axs[0,0].plot(aics)\n",
    "axs[0,0].set_title('AIC (p,0,q,P,0,Q), s=12')\n",
    "axs[0,0].set_xticks(indices)\n",
    "axs[0,0].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "axs[0,1].plot(bics)\n",
    "axs[0,1].set_title('BIC (p,0,q,P,0,Q), s=12')\n",
    "axs[0,1].set_xticks(indices)\n",
    "axs[0,1].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "axs[1,0].plot(rmses)\n",
    "axs[1,0].set_title('RMSE (p,0,q,P,0,Q), s=12')\n",
    "axs[1,0].set_xticks(indices)\n",
    "axs[1,0].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "axs[1,1].plot(acfs)\n",
    "axs[1,1].set_title('MEAN ACF (p,0,q,P,0,Q), s=12')\n",
    "axs[1,1].set_xticks(indices)\n",
    "axs[1,1].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selezionato il modello migliore...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train_data, order=min_aic_model['order'], seasonal_order=min_aic_model['seasonal_order']).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([model.params, model.pvalues], ['value', 'pvalue'])"
   ]
  },
  {
   "source": [
    "## RESIDUAL ANALYSIS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ARIMA(train_data, order=min_aic_model['order'], seasonal_order=min_rmse_model['seasonal_order']).fit()"
   ]
  },
  {
   "source": [
    "## Out-of-sample predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, errors = multiple_forecasts(model=best_model, ts=test_data, times=len(test_data), refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,5))\n",
    "\n",
    "indices = np.arange(0, len(test_data), 3)\n",
    "ticks = [date.strftime('%b') for date in test_data.index]\n",
    "axs[0].set_xticks(indices)\n",
    "axs[0].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "axs[0].plot(errors)\n",
    "\n",
    "pd.Series(predictions, index=test_data.index).plot(ax=axs[1])\n",
    "test_data.plot(ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,5))\n",
    "fig.suptitle('Residual Analysis', fontsize=16, y=1.05)\n",
    "\n",
    "axs[0].plot(errors)\n",
    "axs[0].set_title('Out-of-sample prediction residuals', fontsize=14)\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_ylabel('NH3 (Tg/yr)'.translate(to_pedix))\n",
    "\n",
    "indices = np.arange(0, len(test_data), 2)\n",
    "ticks = [date.strftime('%b') for date in test_data.index]\n",
    "axs[0].set_xticks(indices)\n",
    "axs[0].set_xticklabels(np.array(ticks)[indices], rotation=90)\n",
    "\n",
    "lags = 25\n",
    "autocorrelation_plot(errors[:lags], ax=axs[1], linestyle='dotted', linewidth=4)\n",
    "axs[1].set_title('Out-of-sample prediction autocorrelations', fontsize=14)\n",
    "\n",
    "axs[1].axhline(y=-0.1, color='r', linestyle='-', alpha=.6)\n",
    "axs[1].axhline(y=0.1, color='r', linestyle='-', alpha=.6)\n",
    "\n",
    "indices = np.arange(0, lags, 1)\n",
    "axs[1].set_xticks(indices)\n",
    "axs[1].set_xticklabels(indices)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## In-Sample prediction errors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = best_model.resid\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,5))\n",
    "fig.suptitle('Residual Analysis', fontsize=16, y=1.05)\n",
    "\n",
    "pd.Series(errors).plot(ax=axs[0])\n",
    "axs[0].set_title('In-sample prediction residuals', fontsize=14)\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_ylabel('NH3 (Tg/yr)'.translate(to_pedix))\n",
    "\n",
    "autocorrelation_plot(errors[:24], ax=axs[1], linestyle='dotted', linewidth=4)\n",
    "axs[1].set_title('In-sample prediction autocorrelations', fontsize=14)\n",
    "\n",
    "axs[1].axhline(y=-0.1, color='r', linestyle='-', alpha=.6)\n",
    "axs[1].axhline(y=0.1, color='r', linestyle='-', alpha=.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "best_model.plot_diagnostics(figsize=(10,10))\n",
    "plt.show()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Excluding the first 12 months due to seasonality"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(start=train_data.index[12], end=train_data.index[-1])\n",
    "\n",
    "errors = train_data[12:].values - predictions.values\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,5))\n",
    "fig.suptitle('Residual analysis excluding the first 12 months', fontsize=16,  y=1.05)\n",
    "\n",
    "pd.Series(errors, index=predictions.index).plot(ax=axs[0])\n",
    "axs[0].set_title('In-sample prediction residuals', fontsize=14)\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_ylabel('NH3 (Tg/yr)'.translate(to_pedix))\n",
    "\n",
    "autocorrelation_plot(errors[:24], ax=axs[1], linestyle='dotted', linewidth=4)\n",
    "axs[1].set_title('In-sample prediction autocorrelations', fontsize=14)\n",
    "\n",
    "axs[1].axhline(y=-0.1, color='r', linestyle='-', alpha=.6)\n",
    "axs[1].axhline(y=0.1, color='r', linestyle='-', alpha=.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Autocorrelation\n",
    "\n",
    "Ljung-box test\n",
    "\n",
    "Checks if residuals are white noise:\n",
    "* Accept H0 = no autocorrelations between the series and its first `lags` \n",
    "* Reject H0 = autocorrelations between the series and its first `lags` "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "model_df = len(best_model.param_names) # degrees of freedom of the model\n",
    "\n",
    "lbvalue, pvalue = acorr_ljungbox(errors, lags=12, model_df=model_df)\n",
    "\n",
    "alpha = 0.05\n",
    "print(['Correlated' for i in pvalue[pd.notna(pvalue)] if i < alpha])"
   ]
  },
  {
   "source": [
    "### Normality"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_distributions\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "\n",
    "plot_distributions(pd.Series(errors), 'Errors Distribution', ['NH3 (Tg/yr)','NH3 (Tg/yr)'])\n",
    "\n",
    "jb, pvalue, sk, k = jarque_bera(errors)\n",
    "print('jarque bera test: {}, pvalue: {}'.format('normally distributed' if pvalue > 0.05 else 'not normally distributed', pvalue))\n",
    "\n",
    "ksstat, pvalue = lilliefors(errors)\n",
    "print('lilliefors test: {}, pvalue: {}'.format('normally distributed' if pvalue > 0.05 else 'not normally distributed', pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  null hypothesis is of no heteroskedasticity\n",
    "\n",
    "result = best_model.test_heteroskedasticity(method=None)\n",
    "\n",
    "if result[0, 1] < 0.05: print('Residui eteroschedastici') \n",
    "else: print('Residui omoschedastici')\n",
    "print('pvalue: ', result[0,1])"
   ]
  }
 ]
}